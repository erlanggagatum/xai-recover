{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('../src')\n",
    "# from causal_shapley import causal_shapley, predict_proba\n",
    "from egtoolkit import *\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from egtoolkit import *\n",
    "\n",
    "import random\n",
    "import warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import make_pipeline\n",
    "import itertools\n",
    "from itertools import combinations, permutations, chain\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import mutual_info_score\n",
    "\n",
    "import shap\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "\n",
    "from pgmpy.models import BayesianNetwork\n",
    "from pgmpy.inference import VariableElimination\n",
    "from pgmpy.factors.discrete.CPD import TabularCPD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_cols = ['global_active_power', 'global_reactive_power', 'voltage',\n",
    "                    'global_intensity', 'kitchen', 'laundry', 'climate_control', 'other',\n",
    "                    'weekend', 'month_name', 'season_name', 'day_name']  # list all columns that are categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv('./datasets/2.0-discretized-v2-3-peak-label-encoded.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[False],\n",
       "       [False],\n",
       "       [False],\n",
       "       ...,\n",
       "       [False],\n",
       "       [False],\n",
       "       [False]])"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[['peak_warning']].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "targets = ['peak_label_pred', 'peak_warning', 'no_significant_change', 'lower_than_usual']\n",
    "targets_only = ['peak_label_pred', 'no_significant_change', 'lower_than_usual']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['global_active_power', 'global_reactive_power', 'voltage',\n",
       "       'global_intensity', 'kitchen', 'laundry', 'climate_control', 'other',\n",
       "       'weekend', 'month_name', 'season_name', 'day_name', 'peak_label_pred',\n",
       "       'peak_warning', 'no_significant_change', 'lower_than_usual'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MI Sort"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>climate_control</th>\n",
       "      <th>global_intensity</th>\n",
       "      <th>kitchen</th>\n",
       "      <th>laundry</th>\n",
       "      <th>other</th>\n",
       "      <th>voltage</th>\n",
       "      <th>weekend</th>\n",
       "      <th>peak_warning</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>High</td>\n",
       "      <td>Very High</td>\n",
       "      <td>High</td>\n",
       "      <td>Medium</td>\n",
       "      <td>Very High</td>\n",
       "      <td>Low</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>High</td>\n",
       "      <td>High</td>\n",
       "      <td>Low</td>\n",
       "      <td>Low</td>\n",
       "      <td>High</td>\n",
       "      <td>High</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Very High</td>\n",
       "      <td>Very High</td>\n",
       "      <td>Medium</td>\n",
       "      <td>Medium</td>\n",
       "      <td>Very High</td>\n",
       "      <td>High</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Low</td>\n",
       "      <td>Low</td>\n",
       "      <td>Medium</td>\n",
       "      <td>Low</td>\n",
       "      <td>Medium</td>\n",
       "      <td>Low</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Low</td>\n",
       "      <td>Very High</td>\n",
       "      <td>Low</td>\n",
       "      <td>Low</td>\n",
       "      <td>Very High</td>\n",
       "      <td>Very High</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41668</th>\n",
       "      <td>Low</td>\n",
       "      <td>Low</td>\n",
       "      <td>Low</td>\n",
       "      <td>Low</td>\n",
       "      <td>Medium</td>\n",
       "      <td>Very High</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41669</th>\n",
       "      <td>Medium</td>\n",
       "      <td>Medium</td>\n",
       "      <td>High</td>\n",
       "      <td>Medium</td>\n",
       "      <td>High</td>\n",
       "      <td>Very High</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41670</th>\n",
       "      <td>Low</td>\n",
       "      <td>Medium</td>\n",
       "      <td>Low</td>\n",
       "      <td>High</td>\n",
       "      <td>High</td>\n",
       "      <td>High</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41671</th>\n",
       "      <td>Medium</td>\n",
       "      <td>Low</td>\n",
       "      <td>High</td>\n",
       "      <td>High</td>\n",
       "      <td>Low</td>\n",
       "      <td>Very High</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41672</th>\n",
       "      <td>Low</td>\n",
       "      <td>Low</td>\n",
       "      <td>Low</td>\n",
       "      <td>Low</td>\n",
       "      <td>Low</td>\n",
       "      <td>High</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>41673 rows Ã— 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      climate_control global_intensity kitchen laundry      other    voltage  \\\n",
       "0                High        Very High    High  Medium  Very High        Low   \n",
       "1                High             High     Low     Low       High       High   \n",
       "2           Very High        Very High  Medium  Medium  Very High       High   \n",
       "3                 Low              Low  Medium     Low     Medium        Low   \n",
       "4                 Low        Very High     Low     Low  Very High  Very High   \n",
       "...               ...              ...     ...     ...        ...        ...   \n",
       "41668             Low              Low     Low     Low     Medium  Very High   \n",
       "41669          Medium           Medium    High  Medium       High  Very High   \n",
       "41670             Low           Medium     Low    High       High       High   \n",
       "41671          Medium              Low    High    High        Low  Very High   \n",
       "41672             Low              Low     Low     Low        Low       High   \n",
       "\n",
       "       weekend  peak_warning  \n",
       "0         True         False  \n",
       "1        False         False  \n",
       "2        False         False  \n",
       "3        False         False  \n",
       "4         True         False  \n",
       "...        ...           ...  \n",
       "41668     True         False  \n",
       "41669    False         False  \n",
       "41670    False         False  \n",
       "41671     True         False  \n",
       "41672    False         False  \n",
       "\n",
       "[41673 rows x 8 columns]"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "causal_vars = ['climate_control','global_intensity','kitchen','laundry','other','voltage','weekend', 'peak_warning']\n",
    "dataset_preprocessing = dataset[causal_vars]\n",
    "dataset_preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize LabelEncoder\n",
    "le = LabelEncoder()\n",
    "\n",
    "# Apply LabelEncoder to each column\n",
    "for col in dataset_preprocessing.columns:\n",
    "    dataset_preprocessing[col] = le.fit_transform(dataset_preprocessing[col])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.3748624052229603 0.2918502082238087 0.3196853707866573\n",
      "  0.06627524257671642 0.037659607081020396 0.0503604623530874\n",
      "  0.0006325003465987022 0.09426270891192148]\n",
      " [0.2918502082238087 1.3733068821830432 0.04214078617042706\n",
      "  0.046260120346218125 0.41624975079542736 0.10048726791888057\n",
      "  0.002922910585734295 0.15097777384148847]\n",
      " [0.3196853707866573 0.04214078617042706 1.38286802432115\n",
      "  0.260686249324554 0.010542826604020783 0.044340309486752896\n",
      "  0.0023339804933382724 0.020583936653749024]\n",
      " [0.06627524257671642 0.046260120346218125 0.260686249324554\n",
      "  1.3854443909985528 0.007645556847585777 0.030925773163837364\n",
      "  0.0010848848257274668 0.005839022333192917]\n",
      " [0.037659607081020396 0.4162497507954274 0.010542826604020783\n",
      "  0.007645556847585777 1.379847170104834 0.061686982120370173\n",
      "  0.0022612178958185125 0.06990186563545549]\n",
      " [0.0503604623530874 0.10048726791888057 0.044340309486752896\n",
      "  0.030925773163837364 0.061686982120370173 1.3791596177645482\n",
      "  0.00013741577370590674 0.08480533965934756]\n",
      " [0.0006325003465987022 0.002922910585734295 0.0023339804933382724\n",
      "  0.0010848848257274668 0.0022612178958185125 0.00013741577370590674\n",
      "  0.6015021780313672 0.0003164147462928757]\n",
      " [0.09426270891192148 0.15097777384148847 0.020583936653749024\n",
      "  0.005839022333192917 0.06990186563545549 0.08480533965934756\n",
      "  0.0003164147462928757 0.6365141682948121]]\n"
     ]
    }
   ],
   "source": [
    "# Prepare an empty DataFrame to store mutual information\n",
    "mi_matrix = pd.DataFrame(index=dataset_preprocessing.columns, columns=dataset_preprocessing.columns)\n",
    "\n",
    "# Calculate mutual information for each pair of columns\n",
    "for col1 in dataset_preprocessing.columns:\n",
    "    for col2 in dataset_preprocessing.columns:\n",
    "        mi_matrix.loc[col1, col2] = mutual_info_score(dataset_preprocessing[col1], dataset_preprocessing[col2])\n",
    "\n",
    "print(mi_matrix.values)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features sorted by influence score:\n",
      "global_intensity    1.050889\n",
      "climate_control     0.860726\n",
      "kitchen             0.700313\n",
      "other               0.605948\n",
      "peak_warning        0.426687\n",
      "laundry             0.418717\n",
      "voltage             0.372744\n",
      "weekend             0.009689\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "influence_scores = mi_matrix.sum() - np.diag(mi_matrix)\n",
    "sorted_features = influence_scores.sort_values(ascending=False)\n",
    "print(\"Features sorted by influence score:\")\n",
    "print(sorted_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.08480533965934756"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mi_matrix['peak_warning']['voltage']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "K2 Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from math import factorial as fact\n",
    "\n",
    "def calculate_score(data, parents, child_index, ri, qi, alpha_ijk):\n",
    "    \"\"\"\n",
    "    Calculate the score of a particular node and its parents.\n",
    "    \n",
    "    :param data: The dataset containing the observations.\n",
    "    :param parents: The current set of parent indices for the node.\n",
    "    :param child_index: The index of the child node.\n",
    "    :param ri: The number of possible values for the child variable.\n",
    "    :param qi: The number of unique instantiations of the parents.\n",
    "    :param alpha_ijk: The count of occurrences of child and parent instantiations.\n",
    "    \n",
    "    :return: The calculated score.\n",
    "    \"\"\"\n",
    "    score = 0\n",
    "    for j in range(qi):\n",
    "        Nij = sum(alpha_ijk[j])\n",
    "        score += np.log(fact(ri - 1) / fact(Nij + ri - 1))\n",
    "        for k in range(ri):\n",
    "            score += np.log(fact(alpha_ijk[j][k]))\n",
    "    return score\n",
    "\n",
    "def k2_algorithm(data, node_order, max_parents):\n",
    "    \"\"\"\n",
    "    Implements the K2 algorithm for learning the structure of a Bayesian Network.\n",
    "    \n",
    "    :param data: The dataset to learn from.\n",
    "    :param node_order: The order in which to consider the nodes.\n",
    "    :param max_parents: The maximum number of parents a node can have.\n",
    "    \n",
    "    :return: The structure of the Bayesian Network (list of parents for each node).\n",
    "    \"\"\"\n",
    "    n = data.shape[1]  # Number of nodes\n",
    "    network_structure = [[] for _ in range(n)]\n",
    "\n",
    "    for i, node in enumerate(node_order):\n",
    "        # Set of possible parents for this node is all nodes preceding 'node' in node_order\n",
    "        possible_parents = node_order[:i]\n",
    "        best_score = float('-inf')\n",
    "        node_parents = []\n",
    "\n",
    "        # Iterate through possible parents combinations\n",
    "        while len(node_parents) < max_parents and possible_parents:\n",
    "            for new_parent in possible_parents:\n",
    "                # Test score with the new parent added\n",
    "                current_parents = node_parents + [new_parent]\n",
    "                # Calculate the score with the new parent set\n",
    "                # Note: You would need to implement calculate_alpha_ijk, calculate_ri, and calculate_qi based on your data\n",
    "                ri = calculate_ri(data, node)\n",
    "                qi = calculate_qi(data, current_parents)\n",
    "                alpha_ijk = calculate_alpha_ijk(data, current_parents, node, ri, qi)\n",
    "                current_score = calculate_score(data, current_parents, node, ri, qi, alpha_ijk)\n",
    "\n",
    "                # Update best score and structure\n",
    "                if current_score > best_score:\n",
    "                    best_score = current_score\n",
    "                    node_parents = current_parents\n",
    "\n",
    "            # Remove the added parent from possible parents\n",
    "            possible_parents = [parent for parent in possible_parents if parent not in node_parents]\n",
    "\n",
    "        network_structure[node] = node_parents\n",
    "\n",
    "    return network_structure\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_ri(data, node_index):\n",
    "    \"\"\" Calculate the number of unique values (ri) for the child variable. \"\"\"\n",
    "    return len(np.unique(data[:, node_index]))\n",
    "\n",
    "def calculate_qi(data, parent_indices):\n",
    "    \"\"\" Calculate the number of unique instantiations (qi) of the parent set. \"\"\"\n",
    "    if not parent_indices:\n",
    "        return 1\n",
    "    # Get all unique rows of parent values\n",
    "    unique_parents = np.unique(data[:, parent_indices], axis=0)\n",
    "    return unique_parents.shape[0]\n",
    "\n",
    "def calculate_alpha_ijk(data, parent_indices, child_index, ri, qi):\n",
    "    \"\"\" Calculate the counts (alpha_ijk) of child/parent instantiations. \"\"\"\n",
    "    # Initialize alpha_ijk\n",
    "    alpha_ijk = np.zeros((qi, ri), dtype=int)\n",
    "    \n",
    "    # If there are no parents, count the occurrences of each child value\n",
    "    if not parent_indices:\n",
    "        for k in range(ri):\n",
    "            alpha_ijk[0, k] = np.sum(data[:, child_index] == k)\n",
    "    else:\n",
    "        # Get unique parent instantiations\n",
    "        unique_parents = np.unique(data[:, parent_indices], axis=0)\n",
    "        # Count occurrences of each child value for each parent instantiation\n",
    "        for j, parent_instantiation in enumerate(unique_parents):\n",
    "            # Filter data for the current parent instantiation\n",
    "            parent_mask = np.all(data[:, parent_indices] == parent_instantiation, axis=1)\n",
    "            for k in range(ri):\n",
    "                alpha_ijk[j, k] = np.sum(data[parent_mask, child_index] == k)\n",
    "    \n",
    "    return alpha_ijk\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from math import factorial as fact\n",
    "from itertools import product\n",
    "\n",
    "# Encode the categorical variables\n",
    "le = LabelEncoder()\n",
    "encoded_data = np.array([le.fit_transform(col) for col in zip(*dataset_preprocessing)]).T\n",
    "\n",
    "# Define the node ordering (this is just an example - you should define your own order based on domain knowledge or other criteria)\n",
    "node_order = list(range(encoded_data.shape[1]))\n",
    "\n",
    "def calculate_ri(data, node_index):\n",
    "    \"\"\"Calculate the number of unique values for the child variable.\"\"\"\n",
    "    return len(np.unique(data[:, node_index]))\n",
    "\n",
    "def calculate_qi(data, parent_indices):\n",
    "    \"\"\"Calculate the number of unique instantiations of the parent set.\"\"\"\n",
    "    if not parent_indices:\n",
    "        return 1\n",
    "    unique_parent_instantiations = np.unique(data[:, parent_indices], axis=0)\n",
    "    return len(unique_parent_instantiations)\n",
    "\n",
    "def calculate_alpha_ijk(data, parent_indices, child_index, ri, qi):\n",
    "    \"\"\"Calculate the counts of child/parent instantiations.\"\"\"\n",
    "    if not parent_indices:\n",
    "        # Count occurrences of each value for the child node\n",
    "        return np.array([np.sum(data[:, child_index] == k) for k in range(ri)])\n",
    "    else:\n",
    "        # Count occurrences for each parent instantiation and child value\n",
    "        alpha_ijk = np.zeros((qi, ri), dtype=int)\n",
    "        unique_parent_instantiations = np.unique(data[:, parent_indices], axis=0)\n",
    "        for j, parent_instantiation in enumerate(unique_parent_instantiations):\n",
    "            for k in range(ri):\n",
    "                mask = np.all(data[:, parent_indices] == parent_instantiation, axis=1)\n",
    "                alpha_ijk[j, k] = np.sum(data[mask, child_index] == k)\n",
    "        return alpha_ijk\n",
    "\n",
    "# Replace the k2_algorithm() function with the tailored version for your dataset\n",
    "# ...\n",
    "\n",
    "# Use the tailored K2 algorithm function to learn the structure\n",
    "network_structure = k2_algorithm(encoded_data, node_order, max_parents=2)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "xai2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
